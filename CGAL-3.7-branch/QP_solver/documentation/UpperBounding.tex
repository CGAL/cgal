\documentclass[a4paper]{article}
%\usepackage{html}
\usepackage[dvips]{graphics,color,epsfig}
\usepackage{path}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\F}{\ensuremath{\mathbb{F}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Q}{\ensuremath{\mathbb{Q}}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}

\newtheorem{lemma}{Lemma}
\newtheorem{cor}{Corollary}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}


\title{Upper Bounding}
\author{Frans Wessendorp}
\begin{document}
\maketitle
\section{General Remarks}
\begin{eqnarray}
\label{def:QP_UB}
(QP)\quad minimize&  c^{T}x + x^{T} D x      	&  \nonumber \\
s.t.	 & \sum_{j=0}^{n-1}a_{ij}x_{j} = b_{i}	& i \in E  \nonumber \\
	 & \sum_{j=0}^{n-1}a_{ij}x_{j} \leq b_{i} & i \in I^{\leq} \\
	 & \sum_{j=0}^{n-1}a_{ij}x_{j} \geq b_{i} & i \in I^{\geq}  \nonumber \\
 	 & \mathit{l}_{j} \leq x_{j} \leq u_{j}	  & j \in \{0 \ldots n-1 \}
	 \nonumber
\end{eqnarray}
%\end{equation}
with $D$ positive semi definite, where $I:= I^{\leq} \cup I^{\geq}$ and
$\left| E \right| + \left| I \right| = m$,

The lower and upper bounds, in the finite case,  will be stored in the vectors
$l$ and $u$, $l \leq u$, both of size $\left|O\right|$, where
$O$ denotes the set of original variables. The absence or presence of finite
bounds will be indicated by means of two 0,1 valued vectors $f^{l}$ and $f^{u}$.
\begin{equation}
\label{def: }
\tilde{l}_{k}:=
\left\{
\begin{array}{ll}
-\infty, & \text{if $f^{l}_{k}=0$} \\
l_{k},  & \text{if $f^{l}_{k}=1$}
\end{array}
\right.,
\quad
\tilde{u}_{k}:=
\left\{
\begin{array}{ll}
\infty, & \text{if $f^{u}_{k}=0$} \\
u_{k},  & \text{if $f^{u}_{k}=1$}
\end{array}
\right.
\end{equation}
Thus a variable $x_{k}$ is \emph{free}, if $f_{k}^{u}=0$ and
$f_{k}^{l}=0$, and $x_{k}$ is \emph{fixed}, if $u_{k}=l_{k}$ as well as
$f_{k}^{l}=1$ and $f_{k}^{u}=1$ hold. The set of unrestricted original variables
will be denoted by $U$ and the set of fixed original variables will be denoted
by $F$.

Extending the vectors $f^{l}, f^{u}$ and $l, u$ for the set of slack variables
$S$ and artificial variables $art$ comes naturally, such that we can introduce  
a function $b: (O \setminus F) \cup S \cup art \rightarrow \{-1, 0, 1\}$
indicating which of
the three possible values a nonbasic variable may take with respect to its
bounds,
\begin{equation}
b(k):= \left\{
\begin{array}{ll}
-1
&
\mbox{if $x_{k}=l_{k} \wedge f_{k}^{l}=1$ for $k \in N \setminus F$} \\
0
&
\mbox{if $\left(f_{k}^{l}=1 \Rightarrow x_{k} > l_{k}\right) \wedge
          \left(f_{k}^{u}=1 \Rightarrow x_{k} < u_{k}\right)$
          for $k \in N \setminus F$} \\
1
&
\mbox{if $x_{k}=u_{k} \wedge f_{k}^{u}=1$ for $k \in N \setminus F$} \\
\end{array}
\right.
\end{equation}
where $N$ denotes the set of nonbasic variables. Note that by the very definition of slack and artificial variables $b(k)=-1$ for
$k \in (S \cup art) \cap N$.   
\section{Initialization}
Since the original variables for the initial feasible solution to the auxiliary problem are all nonbasic we have to assign initial values to them. Since for the free or unrestricted variables there is no finite bound to initialize the variables with we will initialize them with the value zero. Due to the amount of computation involved for the initialization of the auxiliary problem we extend the set of original variables that are initialized with zero, $Z$, in the following sense, 
\begin{equation}
\label{def:Z}
Z:=\{ k \in O \left|\right. 0 \in \left[\tilde{l}_{k}, \tilde{u}_{k}\right]\} 
\end{equation}
that is all the original variables that contain zero in their feasible intervall are initialized with zero. For the remaining variables $x_{k}$,
$k \in O \setminus Z$ we initialize the variable with the finite lower bound whenever there is choice,
\begin{equation}
x_{k}^{(0)}:=\left\{
\begin{array}{ll}
0
&
\mbox{for $k \in Z \cap O$} \\
l_{k}
&
\mbox{if $f_{k}^{l}=1, f_{k}^{u}=1$ for $k \in O \setminus Z$} \\
l_{k}
&
\mbox{if $f_{k}^{l}=1, f_{k}^{u}=0$ for $k \in O \setminus Z$} \\
u_{k}
&
\mbox{if $f_{k}^{l}=0, f_{k}^{u}=1$ for $k \in O \setminus Z$}
\end{array}
\right.
\end{equation}


\subsection{The auxiliary problem}
For each of the equality constraints $\sum_{j=0}^{n-1}a_{ij}x_{j}$, $i \in E$,
the original constraint matrix $A$ is augmented by an artificial column 
\begin{equation}
a= \left\{
\begin{array}{ll}
-e_{i}
&
\mbox{if $b_{i}-\sum_{k \in O \setminus Z}a_{ik}x_{k}^{(0)}$} \\
e_{i}
&
\mbox{otherwise}
\end{array}
\right.
\end{equation}
where $e_{i}$ denotes the $i$-th column of the $m \times m$ identity matrix. If the set of inequality constraints with infeasible origin, 
\begin{equation}
I_{inf}:=
\left\{
  i \in I^{\leq}\left|\right.
  b_{i}-\sum_{k \in O \setminus Z}a_{ik}x_{k}^{(0)} < 0
\right\}
\cup
\left\{
  i \in I^{\geq} \left|\right.
  b_{i}-\sum_{k \in O \setminus Z}a_{ik}x_{k}^{(0)} > 0
\right\}
\end{equation}
is nonempty, the original constraint matrix $A$ is augmented by a special artificial column $a_{i}^{s}$
\begin{equation}
a_{i}^{s}= \left\{
\begin{array}{ll}
-1
&
\mbox{if $i \in I^{\leq}, b_{i}-\sum_{k \in O \setminus Z}a_{ik}
    x_{k}^{(0)}<0$} \\
1
&
\mbox{if $i \in I^{\geq}, b_{i}-\sum_{k \in O \setminus Z}a_{ik}
   x_{k}^{(0)}>0$} \\
0
&
\mbox{otherwise}
\end{array}
\right.
\end{equation}


\subsection{The initialization of the auxiliary problem}
Let $i_{0} \in I_{inf}$ be the index of a constraint that has a most infeasible
origin, that is 
\begin{equation}
  \left| b_{i_{0}}-\sum_{k \in O \setminus Z}a_{ik}x_{k}^{(0)} \right|
  \geq 
  \left|b_{i}-\sum_{k \in O \setminus Z}a_{ik}x_{k}^{(0)}\right|,
    \quad i \in I_{inf}
\end{equation}
then $B_{O}$, $B_{S}$ and the initial set of basic and nonbasic constraints
$S_{B}$ and $S_{N}$are initialized as
\begin{equation}
\begin{array}{ccccccc}
  \label{def:headings_init_io}
B_{O}^{(0)} &:=& art && B_{S}^{(0)} &:=& S \setminus
  \{\sigma^{-1}\left(i_{0}\right)\} \\
S_{B}^{(0)} &:=& I \setminus \{i_{0}\} && S_{N}^{(0)} & := & \{ i_{0} \} 
\end{array}
\end{equation}
If on the other hand, $I_{inf}=\emptyset$ then $B_{O}$, $B_{S}$, $S_{B}$ and
$S_{N}$ are initialized as
\begin{equation}
\begin{array}{ccccccc}
\label{def:headings_init_fo}
B_{O}^{(0)} &:=& art && B_{S}^{(0)} &:=& S \\
S_{B}^{(0)} &:=&I && S_{N}^{(0)}&:=& \emptyset
\end{array}
\end{equation}
where $art$ does not contain a special artificial variable.

\section{Optimality conditions}
By the KKT conditions for optimality a feasible solution $x^{*}$ to the
QP~(\ref{def:QP_UB}) is optimal, if there exists an $\left|E\right|$-vector
$\lambda$ and an $\left|I\right|+2n$-vector $\mu \geq 0$,
$\mu=\left({\mu^{\leq}}^{T}\left|\right. {\mu^{\geq}}^{T} \left|\right.
{\mu^{l}}^{T} \left|\right. {\mu^{u}}^{T}\right)^{T}$, such that
\begin{eqnarray*}
c + 2Dx^{*} +A_{E, \bullet}^{T}\lambda
&=&
-A_{I^{\leq}, \bullet}^{T}\mu^{\leq} + A_{I^{\geq}, \bullet}^{T}\mu^{\geq}
+I\mu^{l} -I\mu^{u}  \\
\mu_{i}^{\leq}\left(A_{i, \bullet}x^{*}-b_{i}\right)
&=&
0 \quad\quad\quad i \in I^{\leq}\\
\mu_{i}^{\geq}\left(b_{i}-A_{i, \bullet}x^{*}\right)
&=&
0 \quad\quad\quad i \in I^{\geq}\\
\mu_{i}^{l}\left(l_{i}-x_{i}^{*}\right)
&=& 
0 \quad\quad\quad i= 1 \dots n\\
\mu_{i}^{u}\left(x_{i}^{*}-u_{i}\right)
&=&
0 \quad\quad\quad i=1 \dots n
\end{eqnarray*}
Extending $\lambda$ appropriately and disposing of $\mu^{\leq}$ and $\mu^{\geq}$ in the above conditions we obtain
the following equivalent conditions:
A feasible solution $x^{*}$ to the QP~(\ref{def:QP_UB}) is optimal if there exists an $m$-vector $\lambda$, $\lambda_{i} \geq 0$ for $i \in I^{\leq}$,
$\lambda_{i} \leq 0$ for $i \in I^{\geq}$, and two $n$-vectors $\mu^{l}$ and
$\mu^{u}$, $\mu^{l} \geq 0$, $\mu^{u} \geq 0$ such that
\begin{eqnarray*}
c + 2Dx^{*} +A^{T}\lambda
&=&
I\left(\mu^{l} -\mu^{u}\right)  \\
\lambda^{T}\left(Ax^{*}-b\right)
&=&
0 \\
\mu_{i}^{l}\left(l_{i}-x_{i}^{*}\right)
&=& 
0 \quad\quad\quad i= 1 \dots n\\
\mu_{i}^{u}\left(x_{i}^{*}-u_{i}\right)
&=&
0 \quad\quad\quad i=1 \dots n
\end{eqnarray*}
Replacing $\mu^{l}-\mu^{u}$ by $\mu$ we finally obtain
\begin{lemma}
A feasible solution $x^{*}$ to QP~(\ref{def:QP_UB}) is optimal, if there exists an $m$-vector $\lambda$ and an $n$-vector $\mu$ such that 
\begin{eqnarray}
c + 2Dx^{*} +A^{T}\lambda
&=&
\mu  \\
\lambda^{T}\left(Ax^{*}-b\right)
&=&
0
\end{eqnarray}
and
\begin{eqnarray}
\label{def:mu_opt_cond}
\lambda_{i} \left\{
\begin{array}{ll}
\geq 0, & \text{for $i \in I^{\leq}$} \\
\leq 0, & \text{for $i \in I^{\geq}$}
\end{array}
\right.
&&
\mu_{j} \left\{
\begin{array}{ll}
\geq 0, & \mbox{if $x_{j}^{*}=l_{j} \wedge l_{j}<u_{j}$} \\
= 0,    & \mbox{if $l_{j} < x_{j}^{*} < u_{j}$} \\
\leq 0, & \mbox{if $x_{j}^{*}=u_{j} \wedge l_{j}<u_{j}$}
\end{array}
\right.
\end{eqnarray}
\end{lemma}
For later use we state the KKT conditions for the upper bounded QP with equality constraints only
\begin{lemma}
\label{lem:KKT_QP_UB_eq}
A feasible solution $x^{*}$ to
\begin{eqnarray}
  \mbox{($QP^{u}$)} &minimize& c^{T}x +x^{T}Dx
\nonumber      \\
\label{eq:QP_UB_eq_feas_cons}
    & s.t. & Ax = b  \\
\label{eq:QP_UB_eq_var_feas_cons}
    & & l \leq x \leq u  
\end{eqnarray}
is optimal if and only if there exists an $m$-vector $\lambda$ and an $n$-vector
$\mu$ such that
\begin{eqnarray}
c + 2Dx^{*} +A^{T}\lambda
&=&
\mu  
\end{eqnarray}
and
\begin{equation}
\label{eq:KKT_QP_UB_eq_mu_cond}
\mu_{j} \left\{
\begin{array}{ll}
\geq 0, & \text{if $x_{j}^{*}=l_{j} \wedge l_{j}<u_{j}$} \\
= 0,    & \text{if $l_{j} < x_{j}^{*} < u_{j}$} \\
\leq 0, & \text{if $x_{j}^{*}=u_{j} \wedge l_{j}<u_{j}$}
\end{array}
\right.
\end{equation} 
\end{lemma}
\begin{lemma}
A feasible solution $x^{*}$ to
\begin{eqnarray}
  \mbox{($UQP^{u}$)} &minimize& c^{T}x +x^{T}Dx
\nonumber      \\
\label{eq:UQP_UB_eq_feas_cons}
    & s.t. & Ax = b
\end{eqnarray}
is optimal if and only if there exists an $m$-vector $\lambda$ such that
\begin{eqnarray}
c + 2Dx^{*} +A^{T}\lambda
&=&
\mu  
\end{eqnarray}
\end{lemma}
\begin{cor}
\label{cor:int_QP_UQP}
Any vector $l<x^{*}<u$ satisfying $Ax=b$ is an optimal solution to $(QP^{u})$
if and only if it is an optimal solution to $(UQP^{u})$.
\end{cor}

\section{Pricing}
Testing whether a nonbasic variable $x_{j}$
can improve the solution by entering the current QP-basis is done as follows.
Let $\hat{B}:=B \cup \{j\}, \quad \hat{N}:=N \setminus \{j\}$ and consider the
subproblem
\begin{eqnarray}
  \mbox{(QP($\hat{B}^{u}$))} &minimize& c_{\hat{B} \cup \hat{N}}^{T}
    x_{\hat{B} \cup \hat{N}} +
    x_{\hat{B} \cup \hat{N}}^{T}
    D_{\hat{B} \cup \hat{N}}x_{\hat{B} \cup \hat{N}}
\nonumber      \\
\label{eq:QP_UB_sub_feas_cons}
    & s.t. & A_{\hat{B}}x_{\hat{B}} = b - A_{\hat{N}}
    x_{\hat{N}}  \\
\label{eq:QP_UB_sub_var_feas_cons}
    & & l_{\hat{B}} \leq x_{\hat{B}} \leq u_{\hat{B}},
    \quad x_{\hat{N}} \text{ constant}  
\end{eqnarray}
By the KKT conditions for the upper bounded QP with equality constraints only (Lemma~\ref{lem:KKT_QP_UB_eq}) $x_{\hat{B}}^{*}$ with
$x_{j}^{*} \in \{l_{j}, 0, u_{j}\}$
is an optimal solution to $QP(\hat{B}^{u})$ if and only if there exist vectors
$\lambda$ and $\mu$ such that
\begin{eqnarray}
\label{eq:KKT_opt_cond_sub_prob}
c_{\hat{B}}^{T}+2{x_{\hat{B}}^{*}}^{T}D_{\hat{B}, \hat{B}}
+2{x_{\hat{N}}^{*}}^{T}D_{\hat{N}, \hat{B}}
& = &
-\lambda^{T}A_{\hat{B}}+\mu 
%\\
%\left(x_{\hat{B}}^{*}-u_{\hat{B}}\right)^{T}\mu
%&=&
%0 \\
%\left(l_{\hat{B}}-x_{\hat{B}}^{*}\right)^{T}\mu
%&=&
%0
\end{eqnarray}
where
\begin{equation}
\label{eq:KKT_opt_cond_sub_prob_mu}
\mu_{i}
\left\{
\begin{array}{ll}
\geq 0,
&
\text{if $x_{i}^{*}=l_{i} \wedge l_{i} < u_{i}$} \\
=0,
&
\text{if $l_{i} < x_{i}^{*} < u_{i}$} \\
\leq 0,
&
\text{if $x_{i}^{*}=u_{i} \wedge l_{i} < u_{i}$}
\end{array}
\right.
\end{equation}
Since $l_{B} < x_{B} < u_{B}$, $\mu_{B}=0$ holds using (\ref{def:mu_opt_cond}).
Isolating $x_{j}^{*}$ in (\ref{eq:KKT_opt_cond_sub_prob}) and grouping into $B$
and $j$ components yields
\begin{eqnarray}
\label{eq:KKT_lagrange_id_B}
  c_{B}^{T} + {2x_{B}^{*}}^{T}D_{B,B}
  + 2{x_{\hat{N}}^{*}}^{T}D_{\hat{N},B}
  + 2x_{j}^{*}D_{B,j}^{T} & = & -\lambda^{T} A_{B} \\
\label{eq:KKT_lagrange_id_j}
  c_{j} + 2{x_{B}^{*}}^{T}D_{B,j}
  + 2x_{j}^{*}D_{j,j}
  + 2{x_{\hat{N}}^{*}}^{T}D_{\hat{N},j} & = &
  -\lambda^{T} A_{j} + \mu_{j}
\end{eqnarray}
Equation~(\ref{eq:KKT_lagrange_id_B}) together with the feasibility
constraints~(\ref{eq:QP_UB_sub_feas_cons}), (\ref{eq:QP_UB_sub_var_feas_cons})
determine $x_{B}^{*}$ with $x_{j}^{*} \in \{l_{j}, 0, u_{j}\}$ and $\lambda$ by
the linear equation system
\begin{equation}
\label{def:sol_system}
M_{B}
\left(
\begin{array}{c}
\lambda \\
\hline
x_{B}^{*}
\end{array}
\right)
=
\left(
\begin{array}{c}
b \\
\hline
-c_{B}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{N} \\
\hline
2D_{B, N}
\end{array}
\right)
x_{N}^{*}
%-d_{t}tn
%\left(
%\begin{array}{c}
%A_{j} \\
%\hline
%2D_{B, j}
%\end{array}
%\right)
\end{equation}
with $M_{B}$ defined as
\begin{equation}
M_{B}:=
\left(
\begin{array}{c|c}
0 & A_{B} \\
\hline
A_{B}^{T} & 2D_{B,B}
\end{array}
\right)
\end{equation}

Using the values of $x_{B}^{*}$ and $\lambda$,
Equation~(\ref{eq:KKT_lagrange_id_j}) uniquely determines $\mu_{j}$.
In case $x_{j}^{*}=l_{j}$ and $\mu_{j} < 0$, $x_{\hat{B}}^{*}$ with
$x_{j}^{*}=l_{j}$ cannot
be an optimal solution to $(QP(\hat{B}^{u}))$ because
$\mu_{j}<0 \wedge x_{j}^{*}=l_{j}$ contradicts (\ref{eq:KKT_QP_UB_eq_mu_cond})
in Lemma~\ref{lem:KKT_QP_UB_eq}, likewise $x_{\hat{B}}^{*}$ with
$\mu_{j}>0 \wedge x_{j}^{*}=u_{j}$ cannot be an optimal solution, more
generally the current solution $x_{\hat{B}}^{*}$ with
$x_{j}^{*} \in \{l_{j}, 0, u_{j}\}$ can be improved if and only if
\begin{equation}
\mu_{j}
\left\{
\begin{array}{ll}
< 0    & \text{if $x_{j}^{*}=l_{j} \wedge l_{j} < u_{j}$} \\
\neq 0 & \text{if $x_{j}^{*}=0 \wedge l_{j} < 0 < u_{j}$} \\
> 0    & \text{if $x_{j}^{*}=u_{j} \wedge l_{j} < u_{j}$}
\end{array}
\right.
\end{equation}
The direction of change of an entering variable, $d_{t} \in \{-1, 1\}$, is
according to the above given as 
\begin{equation}
\label{def:direction}
d_{t}:=-sgn(\mu_{j})
\end{equation}


\section{Ratio Test Step~1}
Starting with a QP-basis $B$ and an entering variable $x_{j}$, we want to find a
new basis $B^{\prime} \subseteq B \cup \{j\}$ with a better objective function
value. Define $\hat{B}:=B \cup \{j\}$, then $x_{\hat{B}}^{*}$ with
$x_{j}^{*} \in \{l_{j}, 0, u_{j}\}$ is the optimal solution to
\begin{eqnarray}
\label{QP:UQP_UB_t}
(UQP_{j}^{t}(\hat{B}^{u})) & minimize &
  c_{\hat{B} \cup \hat{N}}^{T}x_{\hat{B} \cup \hat{N}}
  + x_{\hat{B} \cup \hat{N}}^{T}
  D_{\hat{B} \cup \hat{N},\hat{B} \cup \hat{N}}
  x_{\hat{B} \cup \hat{N}}  \nonumber \\
  & s.t & A_{\hat{B}}x_{\hat{B}} =
  b - A_{\hat{N}}x_{\hat{N}} \\
  & & x_{j} = x_{j}(t, d_{t}), \quad x_{\hat{N}} \text{ constant}
  \nonumber
\end{eqnarray}
with
\begin{equation}
x_{j}(t, d_{t})=
\left\{
\begin{array}{ll}
l_{j}+d_{t}t
&
\text{if $x_{j}=l_{j} \wedge l_{j}<u_{j}$} \\
d_{t}t
&
\text{if $x_{j}=0 \wedge l_{j} < 0 < u_{j}$} \\
u_{j}+d_{t}t
&
\text{if $x_{j}=u_{j} \wedge l_{j}<u_{j}$}
\end{array}
\right.
\end{equation}
for $t=0$. Furthermore, $(UQP_{j}^{t}(\hat{B}^{u}))$ has a unique optimal
solution $x_{\hat{B}}^{*}(t)$ for each value of $t$, which is determined by
\begin{equation}
M_{B}
\left(
\begin{array}{c}
\lambda(t, d_{t}) \\
\hline
x_{B}^{*}(t, d_{t})
\end{array}
\right)
=
\left(
\begin{array}{c}
b \\
\hline
-c_{B}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{N} \\
\hline
2D_{B, N}
\end{array}
\right)
x_{N}
+d_{t}t
\left(
\begin{array}{c}
A_{j} \\
\hline
2D_{B, j}
\end{array}
\right)
\end{equation}
This follows from the KKT conditions for (\ref{QP:UQP_UB_t})
(Lemma~\ref{lem:KKT_QP_UB_eq}), the regularity of $M_{B}$, and some elementary
transformations. In the sequel, we use the following equivalent formulation
\begin{equation}
\label{eq:Ratio_Test_1_Opt_sol_t}
\left(
\begin{array}{c}
\lambda(t, d_{t}) \\
\hline
x_{B}^{*}(t, d_{t})
\end{array}
\right)
=
\left(
\begin{array}{c}
\lambda(0) \\
\hline
x_{B}^{*}(0)
\end{array}
\right)
+
d_{t}t
\left(
\begin{array}{c}
q_{\lambda} \\
\hline
q_{x}
\end{array}
\right)
\end{equation}
where
\begin{eqnarray}
\left(
\begin{array}{c}
\lambda(0) \\
\hline
x_{B}^{*}(0)
\end{array}
\right)
&:=&
M_{B}^{-1}
\left[
\left(
\begin{array}{c}
b \\
\hline
-c_{B}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{N} \\
\hline
2D_{B,N}
\end{array}
\right)
x_{N}
\right]
\\
\left(
\begin{array}{c}
q_{\lambda} \\
\hline
q_{x}
\end{array}
\right)
&:=&
M_{B}^{-1}
\left(
\begin{array}{c}
A_{j} \\
\hline
2D_{B,j}
\end{array}
\right)
\end{eqnarray}
While increasing $t$ starting from zero (which improves the current solution),
three things may happen. Either the entering variable $x_{j}$ takes its lower or
upper bound value $l_{j}$ or $u_{j}$, or one of the basic variables $x_{i}$
takes the value of its lower or upper bound $l_{i}$ or $u_{i}$, or a local
minimum of the objective function is reached.

The minimum value of $t$ for the first event, $t_{min}^{j}(d_{t})$, is computed
in the following way for $j \in O \cap N$
\begin{equation}
\label{def:t_min_j}
t_{min}^{j}(d_{t}):=
\left\{
\begin{array}{ll}
u_{j}-l_{j}
&
\text{if $b(j)=-1$} \\
l_{j}
&
\text{if $b(j)=0 \wedge d_{t}=-1$} \\
u_{j}
&
\text{if $b(j)=0 \wedge d_{t}=1$} \\
u_{j}-l_{j}
&
\text{if $b(j)=1$}
\end{array}
\right.
\end{equation}
Note that for $j \in (S \cup art) \cap N$ the first event can never occur.

The minimum value of $t$ for the second event, $t_{min}^{B}(d_{t})$, is computed
in the following way
\begin{equation}
\label{def:t_min_B}
t_{min}^{B}(d_{t}):=\min\{t_{min}^{l}(d_{t}), t_{min}^{u}(d_{t})\}
\end{equation}
where
\begin{eqnarray*}
t_{min}^{l}(d_{t})&:=& \min_{i \in B^{l}}\left(x_{i}-l_{i}\right)/q_{i} \\
t_{min}^{u}(d_{t})&:=& \min_{i \in B^{u}}\left(u_{i}-x_{i}\right)/q_{i} \\
B^{u}(d_{t})&:=&\{i \in B \left|\right. f_{i}^{u}=1 \wedge d_{t}q_{i}<0\} \\
B^{l}(d_{t})&:=&\{i \in B \left|\right. f_{i}^{l}=1 \wedge d_{t}q_{i}>0\} 
\end{eqnarray*} 

To check the third event, we look at the linear function $\mu_{j}(t,d_{t})$
derived from Equation~(\ref{eq:KKT_lagrange_id_j}) and
Equation~(\ref{eq:Ratio_Test_1_Opt_sol_t})
\begin{eqnarray}
\label{eq:mu_j_t_dt}
\mu_{j}(t, d_{t})
&=&
c_{j} + A_{j}^{T}\lambda(t, d_{t})+2D_{B,j}^{T}x_{B}^{*}(t, d_{t})
+2D_{j,j}x_{j}^{*}(t, d_{t})
+2D_{\hat{N},j}^{T}x_{\hat{N}} \nonumber \\
&=&
\mu_{j}+d_{t}t
\left(2D_{j,j}-A_{j}^{T}q_{\lambda}-2D_{B,j}^{T}q_{x}\right) \nonumber \\
&=&
\mu_{j}+d_{t}t\nu
\end{eqnarray}
As soon as $\mu_{j}(t, d_{t})$ becomes zero for some $t > 0$,
$\lambda(t, d_{t})$ and $\mu=0$ fulfill the KKT conditions of
Lemma~\ref{lem:KKT_QP_UB_eq}, thus $x_{\hat{B}}^{*}$ with $x_{j}^{*}(t)=$ is 
an optimal solution to ($QP(\hat{B}^{u})$). The following Lemma shows that
$\hat{B}$ is the new basis in case of the third event.
For later reference let us denote by $t_{min}^{\mu_{j}}(d_{t})$ 
the smallest $t$ for which $\mu_{j}(t, d_{t})$
becomes zero.
\begin{equation}
\label{def:t_min_mu_j}
t_{min}^{\mu_{j}}(d_{t}):=-\mu_{j}(0, d_{t})/\nu
\end{equation}
\begin{lemma}
\label{lem:new_basis}
If $\mu_{j}(t, d_{t})$ in Equation~(\ref{eq:mu_j_t_dt}) becomes zero for some
$t > 0$ before any of the basic variables or the entering variable take the
values of a lower or upper bound, then $\hat{B}$ is the new basis.
\end{lemma}
In case the first event happens, i.e. the entering variable takes the value of
either the lower or upper bound for some $t>0$,
%again Lemma~\ref{lem:new_basis}
%applies; since the third event did not occur $\mu_{j}(t, d_{t})$ still has the
%same sign but by (\ref{eq:KKT_opt_cond_sub_prob_mu}) $x_{\hat{B}}(t, d_{t})$ is
%now an optimal solution to $(QP(\hat{B}^{u}))$.
the entering variable $x_{j}$ remains nonbasic and the pivot step is completed. 

In case the second event happens, i.e. some basic variable $x_{i}$ takes the
value of either its lower or upper bound, we implicitly add the constraint
$x_{i}=l_{i}$ or $x_{i}=u_{i}$ to $(UQP_{j}^{t}(\hat{B}^{u}))$ by removing the
index $i$ from $B$. If $M_{B\setminus \{i\}}$ is regular, we still have a unique
optimal solution to $(UQP_{j}^{t}(\hat{B}^{u} \setminus\{i\}))$ for each value
of $t$ and Ratio Test Step~1 is iterated.
Otherwise we proceed to Ratio Test Step~2.

\section{Ratio Test Step~2}
Let $B$ be the set of basic variables after the last iteration of Ratio Test
Step~1. Since $M_{B}$ has become singular, Equation~(\ref{QP:UQP_UB_t}) does no
longer determine unique solutions to $(UQP_{j}^{t}(\hat{B}^{u}))$ for arbitrary
$t$ (with $\hat{B}=B \cup \{j\}$). Reconsidering the KKT conditions for
$QP(\hat{B}^{u})$, i.e. Equations~(\ref{eq:KKT_opt_cond_sub_prob}) and
(\ref{eq:KKT_opt_cond_sub_prob_mu}), yields
\begin{equation}
\label{eq:rat_test_2}
M_{\hat{B}}
\left(
\begin{array}{c}
\lambda \\
\hline
x_{B}^{*} \\
\hline
x_{j}^{*}
\end{array}
\right)
=
\left(
\begin{array}{c}
b \\
\hline
-c_{B} \\
\hline
-c_{j}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{\hat{N}} \\
\hline
2D_{B, \hat{N}} \\
\hline
2D_{j, \hat{N}}
\end{array}
\right)
x_{\hat{N}}
+\mu_{j}
\left(
\begin{array}{c}
0 \\
\hline
0 \\
\hline
1
\end{array}
\right)
\end{equation}
In case $M_{\hat{B}}$ is singular we proceed directly to Step~3. Otherwise, the
system of linear equations~(\ref{eq:rat_test_2}) has a unique solution for each
value of $\mu_{j}$. The solutions are determined by a linear function in 
$\mu_{j}$, which can be written as
\begin{equation}
\label{eq:x_hat_B_mu_j}
\left(
\begin{array}{c}
\lambda(\mu_{j}) \\
\hline
x_{\hat{B}}^{*}(\mu_{j})
\end{array}
\right)
=
\left(
\begin{array}{c}
\lambda(0) \\
\hline
x_{\hat{B}}^{*}(0)
\end{array}
\right)
+\mu_{j}
\left(
\begin{array}{c}
p_{\lambda} \\
\hline
p_{x_{\hat{B}}}
\end{array}
\right)
\end{equation}
with
\begin{eqnarray}
\left(
\begin{array}{c}
\lambda(0) \\
\hline
x_{\hat{B}}^{*}(0)
\end{array}
\right)
&:=&
M_{\hat{B}}^{-1}
\left[
\left(
\begin{array}{c}
b \\
\hline
-c_{B} \\
\hline
-c_{j}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{\hat{N}} \\
\hline
2D_{B, \hat{N}} \\
\hline
2D_{j, \hat{N}}
\end{array}
\right)
x_{\hat{N}}
\right]
\\
\left(
\begin{array}{c}
p_{\lambda} \\
\hline
p_{x_{B}} \\
\hline
p_{x_{j}}
\end{array}
\right)
&:=&
M_{\hat{B}}^{-1}
\left(
\begin{array}{c}
0 \\
\hline
0 \\
\hline
1
\end{array}
\right)
\end{eqnarray}
Any solution $x_{\hat{B}}(\mu_{j})$ is feasible for $(UQP(\hat{B}^{u}))$, and is
optimal if $\mu_{j}=0$. Let $t_{1}$ be the value of $t$ for which the second
event occured in the last iteration of Ratio Test Step~1, then
$x_{\hat{B}}^{*}(\mu_{j}(t_{1}))$ is the current feasible solution at the
beginning of Ratio Test Step~2.

While increasing or decreasing $\mu_{j}$ from $\mu_{j}(t_{1})$ towards zero
two events may occur. Either one of the basic variables $x_{i}$
takes the value of its finite lower or upper bound $l_{i}$ or $u_{i}$, or a
local minimum of the objective function is reached.

In case of the first event, if some basic variable $x_{k}$ takes the value of
its lower or upper bound, we implicitly add the constraint $x_{k}=l_{k}$ or
$x_{k}=u_{k}$ to $(UQP(\hat{B}^{u}))$ by removing $k$ from $\hat{B}$. If
$M_{\hat{B}\setminus \{k\}}$ stays regular, we still get unique solutions
of~(\ref{eq:rat_test_2})
for arbitrary values of $\mu_{j}$. In this case Ratio Test Step~2 is iterated,
otherwise we continue with Step~3.  

In case the second event happens, i.e. $\mu_{j}$ equals zero, we found an
optimal solution $l_{\hat{B}} < x_{\hat{B}} < u_{\hat{B}}$
to $(UQP(\hat{B}^{u}))$,
which is at the same time an optimal solution to the constrained problem
$(QP(\hat{B}^{u}))$ by Corollary~\ref{cor:int_QP_UQP}. The uniqueness of the
solution follows from the regularity of $M_{\hat{B}}$, which also implies that
$\hat{B}$ is the new basis in that case.

\section{Implementation issues: $w,r$}
Since we want to compute solutions to $UQP_{j}^{t}(\hat{B}^{u})$
according to Equation~(\ref{def:sol_system}),
we have to evaluate 
\begin{equation}
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{S_{B}} \\
\hline
r_{B_{O}} \\
\hline
r_{B_{S}}
\end{array}
\right)
:=
\left(
\begin{array}{c}
A_{C, N} \\
\hline
A_{S_{B}, N} \\
\hline
2D_{B_{O}, N} \\
\hline
2D_{B_{S}, N}
\end{array}
\right)
x_{N}
\end{equation}
furthermore, for the pricing step according to
Equation~(\ref{eq:KKT_lagrange_id_j}) we have to evaluate the components of
\begin{equation}
w_{N}:=2D_{N, N}x_{N}
\end{equation}
among other summands.
Instead of evaluating these two vectors from scratch we shall update
the vectors $r$ and $w$ each time the entities they depend on change.
Since slack and artficial variables have by definition
value zero if they are nonbasic,
only the nonbasic original variables in $N$ contribute to the above
inner products, regardless of the phase, such that by introducing
\begin{eqnarray}
N_{O}:=N \cap O && N_{S}:=N \cap S
\end{eqnarray} 
we may write for $w$
\begin{equation}
w_{N_{O}}:=2D_{N_{O} , N_{O}}x_{N_{O}}
\end{equation}
and for $r$, since we work with the reduced basis matrix
$\check{M}_{B}$,
\begin{equation}
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{S_{B}} \\
\hline
r_{B}
\end{array}
\right)
:=
\left(
\begin{array}{c}
A_{C, N_{O}} \\
\hline
A_{S_{B}, N_{O}} \\
\hline
2D_{B, N_{O}}
\end{array}
\right)
x_{N_{O}},
\end{equation}
the part $r_{S_{B}}$ of the vector $r$ is needed for the computation of the
basic slack variables; we use the feasibility
constraints~(\ref{eq:QP_UB_sub_feas_cons}), sucht that we can express
$x_{B_{S}}$ as
\begin{equation}
x_{B_{S}}
=
A_{S_{B}, B_{S}}^{-1}\left(b_{S_{B}}-r_{S_{B}}-A_{S_{B}, B_{O}}x_{B_{O}}\right)
\end{equation}

\marginpar{computation of $B_{S}$}
\marginpar{type issues for vector $w$, choose right D accessor}


\subsection{The QP-Updates $\mathbf{U_{Z_{1}}}, \mathbf{U_{Z_{2}}},
  \mathbf{U_{Z_{3}}}, \mathbf{U_{Z_{4}}}$ and $\mathbf{U_{1}}, \mathbf{U_{2}},
  \mathbf{U_{3}}, \mathbf{U_{4}}$}
The QP-updates occur only during phaseII for a QP-problem which implies that
we don't have to consider artificial variables in these updates.

\subsubsection{$\mathbf{U_{Z_{1}}}$:$\quad j \in N_{O}$ replaces $i \in B_{O}$:}
\begin{equation}
\label{update:o_z_rep_o}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B}  \\
B_{O}^{\prime}  &:=&  B_{O} \setminus \{i\} \cup \{j\}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S} \\
N_{O}^{\prime}  &:=&  N_{O} \setminus\{j\} \cup \{i\}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S}
\end{array}
\end{equation}

\begin{eqnarray}
w_{N_{O}^{\prime}}^{\prime}
&:=&
\left(
\begin{array}{c}
2D_{N_{O} \setminus\{j\}, N_{O} \setminus\{j\} \cup \{i\}} \\
\hline
2D_{i, N_{O} \setminus\{j\} \cup \{i\}}
\end{array}
\right)
x_{N_{O} \setminus\{j\} \cup \{i\}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
w_{N_{O} \setminus\{j\}} \\
\hline
2D_{i, N_{O}}x_{N_{O}}
\end{array}
\right)
-
\left(
\begin{array}{c}
2D_{N_{O} \setminus\{j\}, j} \\
\hline
2D_{i, j}
\end{array}
\right)
x_{j}
+
\left(
\begin{array}{c}
2D_{N_{O} \setminus\{j\}, i} \\
\hline
2D_{i, i}
\end{array}
\right)
x_{i}^{\prime}
\end{eqnarray}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C, N_{O} \setminus\{j\} \cup \{i\}} \\
\hline
A_{S_{B}, N_{O} \setminus\{j\} \cup \{i\}} \\
\hline
2D_{B_{O} \setminus \{i\}, N_{O} \setminus\{j\} \cup \{i\}} \\
\hline
2D_{j, N_{O} \setminus\{j\} \cup \{i\}}
\end{array}
\right)
x_{N_{O} \setminus\{j\} \cup \{i\}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{S_{B}} \\
\hline
r_{B_{O} \setminus \{i\}} \\
\hline
2D_{j, N_{O}}x_{N_{O}}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{C, j} \\
\hline
A_{S_{B}, j} \\
\hline
2D_{B_{O} \setminus \{i\}, j} \\
\hline
2D_{j, j}
\end{array}
\right)
x_{j}
+
\left(
\begin{array}{c}
A_{C, i} \\
\hline
A_{S_{B}, i} \\
\hline
2D_{B_{O} \setminus \{i\}, i} \\
\hline
2D_{j,i}
\end{array}
\right)
x_{i}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{S_{B}} \\
\hline
r_{B_{O} \setminus \{i\}} \\
\hline
w_{j}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{C, j} \\
\hline
A_{S_{B}, j} \\
\hline
2D_{B_{O} \setminus \{i\}, j} \\
\hline
2D_{j, j}
\end{array}
\right)
x_{j}
+
\left(
\begin{array}{c}
A_{C, i} \\
\hline
A_{S_{B}, i} \\
\hline
2D_{B_{O} \setminus \{i\}, i} \\
\hline
2D_{j,i}
\end{array}
\right)
x_{i}^{\prime}
\end{eqnarray}
where in the last equality for $r_{B_{O}^{\prime}}^{\prime}$ we use $w_{j}$,
such that the only dot product to be computed is for the update
$w_{i}^{\prime}$.

\subsubsection{$\mathbf{U_{Z_{2}}}$:$\quad j \in N_{S}$ replaces $i \in B_{O}$:}
\begin{equation}
\label{update:s_z_rep_o}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C \setminus \{\sigma(j)\}
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B} \cup  \{\sigma(j)\}   \\
B_{O}^{\prime}  &:=&  B_{O} \setminus \{i\}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S} \cup \{j\} \\
N_{O}^{\prime}  &:=&  N_{O} \cup \{i\}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} \setminus \{j\}
\end{array}
\end{equation}

\begin{eqnarray}
w_{N_{O}^{\prime}}^{\prime}
&:=&
\left(
\begin{array}{c}
2D_{N_{O}, N_{O} \cup \{i\}} \\
\hline
2D_{i, N_{O} \cup \{i\}}
\end{array}
\right)
x_{N_{O} \cup \{i\}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
w_{N_{O}} \\
\hline
2D_{i, N_{O}}x_{N_{O}}
\end{array}
\right)
+
\left(
\begin{array}{c}
2D_{N_{O}, i} \\
\hline
2D_{i,i}
\end{array}
\right)
x_{i}^{\prime}
\end{eqnarray}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C \setminus \{\sigma(j)\}, N_{O} \cup \{i\}} \\
\hline
A_{S_{B}, N_{O} \cup \{i\}} \\
\hline
A_{\sigma(j), N_{O} \cup \{i\}} \\
\hline
2D_{B_{O} \setminus \{i\}, N_{O} \cup \{i\}} 
\end{array}
\right)
x_{N_{O} \cup \{i\}}^{\prime} 
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
r_{S_{B}} \\
\hline
A_{\sigma(j), N_{O}}x_{N_{O}} \\
\hline
r_{B_{O} \setminus \{i\}}
\end{array}
\right)
+
\left(
\begin{array}{c}
A_{C \setminus \{\sigma(j)\}, i} \\
\hline
A_{S_{B}, i} \\
\hline
A_{\sigma(j), i} \\
\hline
2D_{B_{O} \setminus \{i\}, i}
\end{array}
\right)
x_{i}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
r_{S_{B}} \\
\hline
r_{\gamma_{C}(\sigma(j))} \\
\hline
r_{B_{O} \setminus \{i\}}
\end{array}
\right)
+
\left(
\begin{array}{c}
A_{C \setminus \{\sigma(j)\}, i} \\
\hline
A_{S_{B}, i} \\
\hline
A_{\gamma_{C}(\sigma(j)), i} \\
\hline
2D_{B_{O} \setminus \{i\}, i}
\end{array}
\right)
x_{i}^{\prime}
\end{eqnarray}
where in the last equality for $r_{\sigma(j)}^{\prime}$ we use
$r_{\gamma_{C}(\sigma(j))}$, such that the only dot product to be computed
is for the update $w_{i}^{\prime}$. 

\subsubsection{$\mathbf{U_{Z_{3}}}$:$\quad j \in N_{O}$ replaces $i \in B_{S}$:}
\begin{equation}
\label{update:o_z_rep_s}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C \cup \{\sigma(i)\}
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B} \setminus  \{\sigma(i)\}   \\
B_{O}^{\prime}  &:=&  B_{O} \cup \{j\}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S} \setminus \{i\} \\
N_{O}^{\prime}  &:=&  N_{O} \setminus \{j\}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} \cup \{i\}  
\end{array}
\end{equation}

\begin{eqnarray}
w_{N_{O}^{\prime}}^{\prime}
&:=&
2D_{N_{O} \setminus \{j\}, N_{O} \setminus \{j\}}
x_{N_{O} \setminus \{j\}}^{\prime}
\nonumber \\
&=&
w_{N_{O} \setminus \{j\}}
-
2D_{N_{O} \setminus \{j\}, j}x_{j}
\end{eqnarray}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C, N_{O} \setminus \{j\}} \\
\hline
A_{\sigma(i), N_{O} \setminus \{j\}} \\
\hline
2D_{B_{O}, N_{O} \setminus \{j\}} \\
\hline
2D_{j, N_{O} \setminus \{j\}} 
\end{array}
\right)
x_{N_{O} \setminus \{j\}}^{\prime} 
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
A_{\sigma(i), N_{O}}x_{N_{O}} \\
\hline
r_{B_{O}} \\
\hline
2D_{j, N_{O}}x_{N_{O}}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{C, j} \\
\hline
A_{\sigma(i), j} \\
\hline
2D_{B_{O}, j} \\
\hline
2D_{j, j}
\end{array}
\right)
x_{j}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{\gamma_{S_{B}}(\sigma(i))} \\
\hline
r_{B_{O}} \\
\hline
w_{j}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{C, j} \\
\hline
A_{\sigma(i), j} \\
\hline
2D_{B_{O}, j} \\
\hline
2D_{j, j}
\end{array}
\right)
x_{j}
\end{eqnarray}
where in the last equality for $r_{\sigma(i)}^{\prime}$ and $r_{j}^{\prime}$ we
use $r_{\gamma_{S_{B}}(\sigma(i))}$ and $w_{j}$ respectively.

\subsubsection{$\mathbf{U_{Z_{4}}}$:$\quad j \in N_{S}$ replaces $i \in B_{S}$:}
\begin{equation}
\label{update:s_z_rep_s}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C \setminus \{\sigma(j)\} \cup \{\sigma(i)\}
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B} \setminus  \{\sigma(i)\} \cup \{\sigma(j)\}   \\
B_{O}^{\prime}  &:=&  B_{O}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S} \setminus \{i\} \cup \{j\} \\
N_{O}^{\prime}  &:=&  N_{O}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} \setminus \{j\} \cup \{i\} 
\end{array}
\end{equation}

\begin{eqnarray}
w_{N_{O}^{\prime}}^{\prime}
&:=&
2D_{N_{O}, N_{O}}x_{N_{O}}^{\prime}
\nonumber \\
&=&
w_{N_{O}}
\end{eqnarray}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C \setminus \{\sigma(j)\}, N_{O}} \\
\hline
A_{\sigma(i), N_{O}} \\
\hline
A_{S_{B} \setminus \{\sigma(i)\}, N_{O}} \\
\hline
A_{\sigma(j), N_{O}} \\
\hline
2D_{B_{O}, N_{O}}
\end{array}
\right)
x_{N_{O}}^{\prime} 
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
A_{\sigma(i), N_{O}}x_{N_{O}} \\
\hline
r_{S_{B} \setminus \{\sigma(i)\}} \\
\hline
A_{\sigma(j), N_{O}}x_{N_{O}} \\
\hline
r_{B_{O}}
\end{array}
\right)
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
r_{\gamma_{S_{B}}(\sigma(i))} \\
\hline
r_{S_{B} \setminus \{\sigma(i)\}} \\
\hline
r_{\gamma_{C}(\sigma(j))} \\
\hline
r_{B_{O}}
\end{array}
\right)
\end{eqnarray}
where in the last equality for $r_{\sigma(i)}^{\prime}$ and
$r_{\sigma(i)}^{\prime}$ we use $r_{\gamma_{S_{B}}(\sigma(i))}$ and
$r_{\gamma_{C}(\sigma(j))}$ respectively.

\subsubsection{$\mathbf{U_{1}}$:$\quad j \in N_{O}$ enters the basis:}
\begin{equation}
\label{update:original_enters_basis}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B}   \\
B_{O}^{\prime}  &:=&  B_{O} \cup \{j\}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S}   \\
N_{O}^{\prime}  &:=&  N_{O} \setminus \{j\}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} 
\end{array}
\end{equation}

\begin{eqnarray}
w_{N_{O}^{\prime}}^{\prime}
&:=&
2D_{N_{O} \setminus \{j\}, N_{O} \setminus \{j\}}
x_{N_{O} \setminus \{j\}}^{\prime}
\nonumber \\
&=&
w_{N_{O} \setminus \{j\}} - 2D_{N_{O} \setminus \{j\}, j}x_{j}
\end{eqnarray}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C, N_{O} \setminus \{j\}} \\
\hline
A_{S_{B}, N_{O} \setminus \{j\}} \\
\hline
2D_{B_{O}, N_{O} \setminus \{j\}} \\
\hline
2D_{j, N_{O} \setminus \{j\}} 
\end{array}
\right)
x_{N_{O} \setminus \{j\}}^{\prime} 
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{S_{B}} \\
\hline
r_{B_{O}} \\
\hline
2D_{j, N_{O}}x_{N_{O}}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{C, j} \\
\hline
A_{S_{B}, j} \\
\hline
2D_{B_{O}, j} \\
\hline
2D_{j, j}
\end{array}
\right)
x_{j}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{S_{B}} \\
\hline
r_{B_{O}} \\
\hline
w_{j}
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{C, j} \\
\hline
A_{S_{B}, j} \\
\hline
2D_{B_{O}, j} \\
\hline
2D_{j, j}
\end{array}
\right)
x_{j}
\end{eqnarray}
where in the last equality for $r_{j}^{\prime}$ we use $w_{j}$. 

\subsubsection{$\mathbf{U_{2}}$:$\quad i \in B_{O}$ leaves the basis:}
\begin{equation}
\label{update:original_leaves_basis}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B}   \\
B_{O}^{\prime}  &:=&  B_{O} \setminus \{i\}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S}   \\
N_{O}^{\prime}  &:=&  N_{O} \cup \{i\}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} 
\end{array}
\end{equation}

\begin{eqnarray}
w_{N_{O}^{\prime}}^{\prime}
&:=&
\left(
\begin{array}{c}
2D_{N_{O}, N_{O} \cup \{i\}} \\
\hline
2D_{i, N_{O} \cup \{i\}}
\end{array}
\right)
x_{N_{O} \cup \{i\}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
w_{N_{O}} \\
\hline
2D_{i, N_{O}}x_{N_{O}}
\end{array}
\right)
+
\left(
\begin{array}{c}
2D_{N_{O}, i} \\
\hline
2D_{i, i}
\end{array}
\right)
x_{i}^{\prime}
\end{eqnarray}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C, N_{O} \cup \{i\}} \\
\hline
A_{S_{B}, N_{O} \cup \{i\}} \\
\hline
2D_{B_{O} \setminus \{i\}, N_{O} \cup \{i\}} 
\end{array}
\right)
x_{N_{O} \cup \{i\}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{S_{B}} \\
\hline
r_{B_{O} \setminus \{i\}}
\end{array}
\right)
+
\left(
\begin{array}{c}
A_{C, i} \\
\hline
A_{S_{B}, i} \\
\hline
2D_{B_{O} \setminus \{i\}, i}
\end{array}
\right)
x_{i}^{\prime}
\end{eqnarray}
The only dot product to be computed is for the update of $w_{i}^{\prime}$.

\subsubsection{$\mathbf{U_{3}}$:$\quad j \in N_{S}$ enters the basis:}
\begin{equation}
\label{update:slack_enters_basis}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C \setminus \{\sigma(j)\}
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B} \cup \{\sigma(j)\}  \\
B_{O}^{\prime}  &:=&  B_{O}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S} \cup \{j\}  \\
N_{O}^{\prime}  &:=&  N_{O}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} \setminus \{j\} 
\end{array}
\end{equation}

\begin{eqnarray}
w_{N_{O}^{\prime}}^{\prime}
&:=&
2D_{N_{O}, N_{O}}x_{N_{O}}^{\prime}
\nonumber \\
&=&
w_{N_{O}}
\end{eqnarray}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C \setminus \{\sigma(j)\}, N_{O}} \\
\hline
A_{S_{B}, N_{O}} \\
\hline
A_{\sigma(j), N_{O}} \\
\hline
2D_{B_{O}, N_{O}}
\end{array}
\right)
x_{N_{O}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
r_{S_{B}} \\
\hline
A_{\sigma(j), N_{O}}x_{N_{O}} \\
\hline
r_{B_{O}}
\end{array}
\right)
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
r_{S_{B}} \\
\hline
r_{\gamma_{C}(\sigma(j))} \\
\hline
r_{B_{O}}
\end{array}
\right)
\end{eqnarray}
where in the last equality for $r_{\sigma(j)}^{\prime}$ we used
$r_{\gamma_{C}(\sigma(j))}$.

\subsubsection{$\mathbf{U_{4}}$:$\quad i \in B_{S}$ leaves the basis:}
\begin{equation}
\label{update:slack_leaves_basis}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C \cup \{\sigma(i)\}
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B} \setminus \{\sigma(i)\}  \\
B_{O}^{\prime}  &:=&  B_{O}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S} \setminus \{i\}  \\
N_{O}^{\prime}  &:=&  N_{O}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} \cup \{i\} 
\end{array}
\end{equation}

\begin{eqnarray}
w_{N_{O}^{\prime}}^{\prime}
&:=&
2D_{N_{O}, N_{O}}x_{N_{O}}^{\prime}
\nonumber \\
&=&
w_{N_{O}}
\end{eqnarray}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C, N_{O}} \\
\hline
A_{\sigma(i), N_{O}} \\
\hline
A_{S_{B} \setminus \{\sigma(i)\}, N_{O}} \\
\hline
2D_{B_{O}, N_{O}} 
\end{array}
\right)
x_{N_{O}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
A_{\sigma(i), N_{O}}x_{N_{O}} \\
\hline
r_{S_{B} \setminus \{\sigma(i)\}} \\
\hline
r_{B_{O}}
\end{array}
\right)
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{\gamma_{S_{B}}(\sigma(i))} \\
\hline
r_{S_{B} \setminus \{\sigma(i)\}} \\
\hline
r_{B_{O}}
\end{array}
\right)
\end{eqnarray}
where in the last equatlity for $r_{\sigma(i)}^{\prime}$ we used
$r_{\gamma_{S_{B}}(\sigma(i))}$.


\subsection{The LP-Updates $\mathbf{U_{5}}, \mathbf{U_{6}}, 
  \mathbf{U_{7}}, \mathbf{U_{8}}$}
The LP-updates of the basis inverse occur during phaseI and phaseII of an LP
problem and during phaseI of a QP-problem. We therefore have $D=0$ and 
$r_{B_{O}}=0$ throughout.  

\subsubsection{$\mathbf{U_{5}}$:$\quad j \in N_{O}$ replaces $i \in B_{O}$:}
\begin{equation}
\label{update:o_rep_o}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B}  \\
B_{O}^{\prime}  &:=&  B_{O} \setminus \{i\} \cup \{j\}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S}   \\
N_{O}^{\prime}  &:=&  N_{O}  \setminus \{j\} \cup \{i\}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} 
\end{array}
\end{equation}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C, N_{O}  \setminus \{j\} \cup \{i\}} \\
\hline
A_{S_{B}, N_{O} \setminus \{j\} \cup \{i\}} \\
\hline
0
\end{array}
\right)
x_{N_{O}  \setminus \{j\} \cup \{i\}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{S_{B}} \\
\hline
0
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{C, j} \\
\hline
A_{S_{B}, j} \\
\hline
0
\end{array}
\right)
x_{j}
+
\left(
\begin{array}{c}
A_{C, i} \\
\hline
A_{S_{B}, i} \\
\hline
0
\end{array}
\right)
x_{i}^{\prime}
\end{eqnarray}

Note that this update of $w$ and $r$ comes in phaseI in 4 varieties,
depending on whether $j \in art$ or $i \in art$ or not.

\subsubsection{$\mathbf{U_{6}}$:$\quad j \in N_{S}$ replaces $i \in B_{S}$:}
\begin{equation}
\label{update:s_rep_s}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C \setminus \{\sigma(j)\} \cup \{\sigma(i)\}
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B} \setminus \{\sigma(i)\} \cup \{\sigma(j)\} \\
B_{O}^{\prime}  &:=&  B_{O}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S} \setminus \{i\} \cup \{j\}  \\
N_{O}^{\prime}  &:=&  N_{O}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} \setminus \{j\} \cup \{i\} 
\end{array}
\end{equation}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C \setminus \{\sigma(j)\}, N_{O}} \\
\hline
A_{\sigma(i), N_{O}} \\
\hline
A_{S_{B} \setminus \{\sigma(i)\}, N_{O}} \\
\hline
A_{\sigma(j), N_{O}} \\
\hline
0
\end{array}
\right)
x_{N_{O}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
A_{\sigma(i), N_{O}}x_{N_{O}} \\
\hline
r_{S_{B} \setminus \{\sigma(i)\}} \\
\hline
A_{\sigma(j), N_{O}}x_{N_{O}} \\
\hline
0
\end{array}
\right)
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
r_{\gamma_{S_{B}}(\sigma(i))} \\
\hline
r_{S_{B} \setminus \{\sigma(i)\}} \\
\hline
r_{\gamma_{C}(\sigma(j))} \\
\hline
0
\end{array}
\right)
\end{eqnarray}
where in the last equality for $r_{\sigma(i)}^{\prime}$ and
$r_{\sigma(i)}^{\prime}$ we use $r_{\gamma_{S_{B}}(\sigma(i))}$ and
$r_{\gamma_{C}(\sigma(j))}$ respectively.


\subsubsection{$\mathbf{U_{7}}$:$\quad j \in N_{O}$ replaces $i \in B_{S}$:}
\begin{equation}
\label{update:o_rep_s}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C \cup \{\sigma(i)\}
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B} \setminus \{\sigma(i)\} \\
B_{O}^{\prime}  &:=&  B_{O} \cup \{j\}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S} \setminus \{i\}  \\
N_{O}^{\prime}  &:=&  N_{O} \setminus \{j\}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} \cup \{i\} 
\end{array}
\end{equation}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C, N_{O} \setminus \{j\}} \\
\hline
A_{\sigma(i), N_{O} \setminus \{j\}} \\
\hline
A_{S_{B} \setminus \{\sigma(i)\}, N_{O} \setminus \{j\}} \\
\hline
0
\end{array}
\right)
x_{N_{O} \setminus \{j\}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
A_{\sigma(i), N_{O}}x_{N_{O}} \\
\hline
r_{S_{B} \setminus \{\sigma(i)\}} \\
\hline
0
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{C, j} \\
\hline
A_{\sigma(i), j} \\
\hline
A_{S_{B} \setminus \{\sigma(i)\}, j} \\
\hline
0
\end{array}
\right)
x_{j}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C} \\
\hline
r_{\gamma_{S_{B}}(\sigma(i))} \\
\hline
r_{S_{B} \setminus \{\sigma(i)\}} \\
\hline
0
\end{array}
\right)
-
\left(
\begin{array}{c}
A_{C, j} \\
\hline
A_{\sigma(i), j} \\
\hline
A_{S_{B} \setminus \{\sigma(i)\}, j} \\
\hline
0
\end{array}
\right)
x_{j}
\end{eqnarray}
where in the last equality for $r_{\sigma(i)}^{\prime}$ we used
$r_{\gamma_{S_{B}}(\sigma(i))}$. Note that this update of $w$ and $r$ comes
in phaseI in 2 varieties, depending on whether $j \in art$ or not.

\subsubsection{$\mathbf{U_{8}}$:$\quad j \in N_{S}$ replaces $i \in B_{O}$:}
\begin{equation}
\label{update:s_rep_o}
\begin{array}{ccccccc}
C^{\prime}      &:=&  C \setminus \{\sigma(j)\}
&\quad\quad&
S_{B}^{\prime}  &:=&  S_{B} \cup \{\sigma(j)\} \\
B_{O}^{\prime}  &:=&  B_{O} \setminus \{i\}
&\quad\quad&
B_{S}^{\prime}  &:=&  B_{S} \cup \{j\}  \\
N_{O}^{\prime}  &:=&  N_{O} \cup \{i\}
&\quad\quad&
N_{S}^{\prime}  &:=&  N_{S} \setminus \{j\} 
\end{array}
\end{equation}

\begin{eqnarray}
\left(
\begin{array}{c}
r_{C^{\prime}}^{\prime} \\
\hline
r_{S_{B}^{\prime}}^{\prime} \\
\hline
r_{B_{O}^{\prime}}^{\prime}
\end{array}
\right)
&:=&
\left(
\begin{array}{c}
A_{C \setminus \{\sigma(j)\}, N_{O} \cup \{i\}} \\
\hline
A_{S_{B}, N_{O} \cup \{i\}} \\
\hline
A_{\sigma(j), N_{O} \cup \{i\}} \\
\hline
0
\end{array}
\right)
x_{N_{O} \cup \{i\}}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
r_{S_{B}} \\
\hline
A_{\sigma(j), N_{O}} \\
\hline
0
\end{array}
\right)
+
\left(
\begin{array}{c}
A_{C \setminus \{\sigma(j)\}, i} \\
\hline
A_{S_{B}, i} \\
\hline
A_{\sigma(j), i} \\
\hline
0
\end{array}
\right)
x_{i}^{\prime}
\nonumber \\
&=&
\left(
\begin{array}{c}
r_{C \setminus \{\sigma(j)\}} \\
\hline
r_{S_{B}} \\
\hline
r_{\gamma_{C}((\sigma(j))} \\
\hline
0
\end{array}
\right)
+
\left(
\begin{array}{c}
A_{C \setminus \{\sigma(j)\}, i} \\
\hline
A_{S_{B}, i} \\
\hline
A_{\sigma(j), i} \\
\hline
0
\end{array}
\right)
x_{i}^{\prime}
\end{eqnarray}
where in the last equality for $r_{\sigma(j)}^{\prime}$ we used
$r_{\gamma_{C}((\sigma(j))}$. Note that this update of $w$ and $r$ comes in
phaseI in 2 varieties, depending on $i \in art$ or not.

\subsection{The upper bounding - Update $\mathbf{U_{9}}$}

\subsubsection{$\mathbf{U_{9}}$:$\quad j \in N_{O}$ enters and leaves basis:}

\section{Pricing strategies implementation issues}
The $\mu_{j}$, $j \in N$, for the pricing step are computed according to
Equation~(\ref{eq:KKT_lagrange_id_j}),
that is
\begin{equation}
\mu_{j}=
  c_{j} + 2{x_{B}^{*}}^{T}D_{B,j}
  +\lambda^{T} A_{j}
  + 2x_{j}^{*}D_{j,j}
  + 2{x_{\hat{N}}^{*}}^{T}D_{\hat{N},j}
\end{equation}
The sum of the last two summands of the right hand side remains constant
during pricing for a given basis and changes only during the Ratio Test steps.
For reasons of efficiency we compute $2x_{N}^{T}D_{N,j}$ once at the
beginning of phaseI and update it incrementally afterwards with each change
of the basis heading.

Due to the fact that with upper bounding a nonbasic variable selected 
as entering variable by the 
pricing step may have to be increased or decreased, 
the pricing step not
only has to deliver an entering variable $x_{j}$, $j \in N$, if the current
solution is suboptimal, but according to Definition~(\ref{def:direction}), a
direction $d_{t}=-sign(\mu_{j})$, indicating whether the entering variable
$x_{j}$ is to be increased or decreased as well. So if $d_{t}=1$ the entering
variable is to be increased, otherwise it is to be decreased.

\subsection{Full exact pricing}
Generalizing the full exact pricing algorithm we introduce the following subsets of the set of nonbasic variables $N$
\begin{eqnarray}
N_{l}&:=&\{k \in N \setminus F\left|\right. b\left(k\right)=-1\} \\
N_{0}&:=&\{k \in N \setminus F\left|\right. b\left(k\right)=0\} \\
N_{u}&:=&\{k \in N \setminus F\left|\right. b\left(k\right)=1\}
\end{eqnarray}
\paragraph{Full exact pricing with explicit bounds}
\begin{tabbing}
\texttt{FULL\_EXACT\_PRICING$(N)$} \\
\texttt{IF} \= \kill
\> \texttt{$j_{l}:=\arg\min_{k \in N_{l} \cup
                               N_{0}}\mu_{k}$}  \\
\> \texttt{$j_{u}:=\arg\max_{k \in N_{u} \cup
                               N_{0}}\mu_{k}$}  \\
\> \texttt{$j:=\arg\max_{k \in \{j_{l}, j_{u}\}}\left|\mu_{k}\right|$}  \\
\> \texttt{IF $\mu_{j} \neq 0$ THEN} \\
\texttt{IFIF} \= \kill
\> \texttt{IF $j = j_{l}$ THEN $d_{t}:=1$ ELSE $d_{t}:=-1$ END} \\
%\texttt{IFIFIF} \= \kill
%\> \texttt{dir:=1} \\
%\texttt{IFIF} \= \kill
%\> \texttt{ELSE} \\
%\texttt{IFIFIF} \= \kill
%\> \texttt{dir=-1} \\
%\texttt{IFIF} \= \kill
%\> \texttt{END} \\
\> \texttt{RETURN $(j, d_{t})$} \\
\texttt{IF} \= \kill
\> \texttt{ELSE} \\
\texttt{IFIF} \= \kill
\> \texttt{RETURN \emph{optimal}} \\
\texttt{IF} \= \kill
\> \texttt{END} \\
\texttt{END}
\end{tabbing}


\subsection{Partial exact pricing}
Generalizing the partial pricing algorithm given in \cite{Sven}, section 6.4.1 for explicit bounds we introduce the following subsets of the active set $\mathcal{A} \subseteq N \setminus F$ 
\begin{eqnarray}
\mathcal{A}_{l}&:=&\{k \in \mathcal{A}\left|\right. b\left(k\right)=-1\} \\
\mathcal{A}_{0}&:=&\{k \in \mathcal{A}\left|\right. b\left(k\right)=0\} \\
\mathcal{A}_{u}&:=&\{k \in \mathcal{A}\left|\right. b\left(k\right)=1\}
\end{eqnarray}
\paragraph{Partial exact pricing with explicit bounds}
\begin{tabbing}
\texttt{PARTIAL\_EXACT\_PRICING$(\mathcal{A})$} \\
\texttt{IF} \= \kill
\> \texttt{$j_{l}:=\arg\min_{k \in \mathcal{A}_{l} \cup
                               \mathcal{A}_{0}}\mu_{k}$}  \\
\> \texttt{$j_{u}:=\arg\max_{k \in \mathcal{A}_{u} \cup
                               \mathcal{A}_{0}}\mu_{k}$}  \\
\> \texttt{$j:=\arg\max_{k \in \{j_{l}, j_{u}\}}\left|\mu_{k}\right|$}  \\
\> \texttt{IF $\left(\mu_{j} < 0 \wedge b\left(j\right) \leq 0 \right)
   \vee \left(\mu_{j} > 0 \wedge b\left(j\right) \geq 0 \right)$} \\
\texttt{IFIF} \= \kill
\> \texttt{IF $j=j_{l}$ THEN $d_{t}:=1$ ELSE $d_{t}:=-1$ END} \\
\> \texttt{RETURN $(j, d_{t})$} \\
\texttt{IF} \= \kill
\> \texttt{ELSE} \\
\texttt{IFIF} \= \kill
\> \texttt{$V:=\{k \in N \setminus F \setminus \mathcal{A} \left|\right.
    \mu_{k} < 0 \wedge b\left(k\right) \leq 0 \vee
    \mu_{k} > 0 \wedge b\left(k\right) \geq 0\}$} \\
\> \texttt{IF $V=0$ THEN} \\
\texttt{IFIFIF} \= \kill  
\> \texttt{RETURN \emph{optimal}} \\
\texttt{IFIF} \= \kill
\> \texttt{ELSE} \\
\texttt{IFIFIF} \= \kill
\> \texttt{$\mathcal{A}:=\mathcal{A} \cup V$} \\
\> \texttt{RETURN $\arg\max_{j \in V}\left|\mu_{j}\right|$} \\
\texttt{IFIF} \= \kill
\> \texttt{END} \\
\texttt{IF} \= \kill
\> \texttt{END}
\end{tabbing}
\subsection{Full filtered pricing}
\subsection{Partial filtered pricing}

\section{Ratio Test Step implementation issues}

\subsection{Ratio Test Step~1 implementation issues}
We distinguish three events:
\begin{enumerate}
\item The entering variable $x_{j}$ takes the value of its finite upper,
$u_{j}$, or lower bound, $l_{j}$.
\item A basic variable $x_{i}$ takes the value of its finite upper or lower bound.
\item $\mu_{j}(x_{j}(t, d_{t}))$ becomes zero.
\end{enumerate}

\paragraph{$\mathbf{t_{min}^{j}(d_{t}):}$}


\paragraph{$\mathbf{t_{min}^{B}(d_{t}):}$}
Since slack and artificial variables all have the same upper and lower bounds,
we don't want to keep the vectors $f^{l}$, $f^{u}$ and the function
$b: O \cup S \cup art \rightarrow \{-1,0,1\}$ explicitly for the artificial and
slack variables. 
All of the variables comprising $B_{S}$ have the same bounds, whereas because of
$art \subseteq O$ the variables of the set $B_{O}$ do not share this property in
the sense that for $art \subseteq B_{O}$ the bounds are implicitly given and for
$B_{O} \setminus art$ they are defined by $f^{l}, l$ and $f^{u}, u$, such that
we cannot use one function for both the ratio test for the set of basic
original variables $B_{O}$ and the set of basic slack variables $B_{S}$ without
incurring computational overhead for the latter set.
%\begin{algorithm}
%\caption{Ratio Test Step~1 with upper bounding}
%\label{alg:ratio_test_step_1_0}
\begin{algorithmic}
\Function{ratio\_test\_1\_\_t\_i\_B\_O}{$B_{O}, x_{B_{O}}, q_{B_{O}}, d_{t}$}
\State $i_{min} \gets -1, \quad     d_{min} \gets 1, \quad  q_{min} \gets 0$
\If{$d_{t}=1$}
    \ForAll{$i \gets 0,  \left|B_{O}\right| - 1$}
        \If{$q_{B_{O}}[i] > 0$}
            \Comment check for lower bounds
            \If{$B_{O}[i] < n$}
                \Comment original variable
                \If{$f_{B_{O}}^{l}[i]=1$}
                    \If{$d_{min}*q_{B_{O}}[i] > (x_{B_{O}}[i]-l[B_{O}[i]])*q_{min}$}
                        \State $i_{min} \gets B_{O}[i], \quad lower \gets true$
                        \State $d_{min} \gets x_{B_{O}}[i]-l[B_{O}[i]],
                            \quad q_{min} \gets q_{B_{O}}[i]$
                    \EndIf
                \EndIf
            \Else
                \Comment auxiliary variable
                \If{$d_{min}*q_{B_{O}}[i] > x_{B_{O}}[i]*q_{min}$}
                    \State $i_{min} \gets B_{O}[i], \quad lower \gets true$
                    \State $d_{min} \gets x_{B_{O}}[i],
                        \quad q_{min} \gets q_{B_{O}}[i]$
                \EndIf
            \EndIf
        \ElsIf{$q_{B_{O}}[i] < 0$}
            \Comment check for upper bounds
            \If{$B_{O}[i] < n \wedge f_{B_{O}}^{u}[i]=1$}
                \If{$d_{min}*-q_{B_{O}}[i] > (u[B_{O}[i]]-x_{B_{O}}[i])*q_{min}$}
                    \State $i_{min} \gets B_{O}[i], \quad lower \gets false$
                    \State $d_{min} \gets u[B_{O}[i]]-x_{B_{O}}[i],
                        \quad q_{min} \gets -q_{B_{O}}[i]$
                \EndIf
            \EndIf
        \EndIf
    \EndFor
%    \ForAll{$i \gets 0, \left|B_{S}\right| - 1$}
%        \If{$q_{B_{S}}[i] > 0$}
%            \If{$d_{min}*q_{B_{S}}[i] > x_{B_{S}}[i]*q_{min}$}
%                \State $i_{min} \gets B_{S}[i],
%                    \quad d_{min} \gets x_{B_{S}}[i],
%                    \quad q_{min} \gets q_{B_{S}}[i]$
%            \EndIf	
%        \EndIf 
%    \EndFor
\Else
    \Comment $d_{t}=-1$
    \ForAll{$i \gets 0,  \left|B_{O}\right| - 1$}
        \If{$q_{B_{O}}[i] < 0$}
            \Comment check for lower bounds
            \If{$B_{O}[i] < n$}
                \Comment original variable
                \If{$f_{B_{O}}^{l}[i]=1$}
                    \If{$d_{min}*-q_{B_{O}}[i] > (x_{B_{O}}[i]-l[B_{O}[i]])*q_{min}$}
                        \State $i_{min} \gets B_{O}[i], \quad lower \gets true$
                        \State $d_{min} \gets x_{B_{O}}[i]-l[B_{O}[i]],
                            \quad q_{min} \gets -q_{B_{O}}[i]$
                    \EndIf
                \EndIf
            \Else
                \Comment auxiliary variable
                \If{$d_{min}*-q_{B_{O}}[i] > x_{B_{O}}[i]*q_{min}$}
                    \State $i_{min} \gets B_{O}[i], \quad lower \gets true$
                    \State $d_{min} \gets x_{B_{O}}[i],
                        \quad q_{min} \gets -q_{B_{O}}[i]$
                \EndIf
            \EndIf
        \ElsIf{$q_{B_{O}}[i] > 0$}
            \Comment check for upper bounds
            \If{$B_{O}[i] < n \wedge f_{B_{O}}^{u}[i]=1$}
                \If{$d_{min}*q_{B_{O}}[i] > (u[B_{O}[i]]-x_{B_{O}}[i])*q_{min}$}
                    \State $i_{min} \gets B_{O}[i], \quad lower \gets false$
                    \State $d_{min} \gets u[B_{O}[i]]-x_{B_{O}}[i],
                        \quad q_{min} \gets q_{B_{O}}[i]$
                \EndIf
            \EndIf
        \EndIf
    \EndFor
%    \ForAll{$i \gets 0, \left|B_{S}\right| - 1$}
%        \If{$q_{B_{S}}[i] < 0$}
%            \If{$d_{min}*-q_{B_{S}}[i] > x_{B_{S}}[i]*q_{min}$}
%                \State $i_{min} \gets B_{S}[i],
%                    \quad d_{min} \gets x_{B_{S}}[i],
%                    \quad q_{min} \gets -q_{B_{S}}[i]$
%            \EndIf	
%        \EndIf 
%    \EndFor
\EndIf
\State \textbf{return} $(i_{min}, d_{min}, q_{min})$
\EndFunction
\end{algorithmic}
%\end{algorithm}
Due to the fact that all of the upper and lower bounds for the basic slack
variables are implicitly given the corresponding function for the basic slack
variables is somewhat simpler. Since we distinguish between quadratic programs
that have inequality constraints and ones that have equality constraints only
by the compile time tag \texttt{Has\_no\_inequalities}, the function
is statically dispatched. We list the non-void case:
\begin{algorithmic}
\Function{ratio\_test\_1\_\_t\_i\_B\_S}{$B_{S}, x_{B_{S}}, q_{B_{S}}, d_{t}$}
\State $i_{min} \gets -1, \quad     d_{min} \gets 1, \quad  q_{min} \gets 0$
\If{$d_{t}=1$}
    \ForAll{$i \gets 0, \left|B_{S}\right| - 1$}
        \If{$q_{B_{S}}[i] > 0$}
            \If{$d_{min}*q_{B_{S}}[i] > x_{B_{S}}[i]*q_{min}$}
                \State $i_{min} \gets B_{S}[i],
                    \quad d_{min} \gets x_{B_{S}}[i],
                    \quad q_{min} \gets q_{B_{S}}[i]$
            \EndIf	
        \EndIf 
    \EndFor
\Else
    \ForAll{$i \gets 0, \left|B_{S}\right| - 1$}
        \If{$q_{B_{S}}[i] < 0$}
            \If{$d_{min}*-q_{B_{S}}[i] > x_{B_{S}}[i]*q_{min}$}
                \State $i_{min} \gets B_{S}[i],
                    \quad d_{min} \gets x_{B_{S}}[i],
                    \quad q_{min} \gets -q_{B_{S}}[i]$
            \EndIf	
        \EndIf 
    \EndFor
\EndIf
\State \textbf{return} $(i_{min}, d_{min}, q_{min})$
\EndFunction
\end{algorithmic}
\paragraph{$\mathbf{t_{min}^{\mu_{j}}(d_{t}):}$}
According to Equations~(\ref{def:t_min_mu_j}), (\ref{eq:mu_j_t_dt}) as well
as~(\ref{eq:KKT_lagrange_id_j}) we compute $\mu_{j}(t, d_{t})$ for $t=0$ 
\begin{algorithmic}
\Function{ratio\_test\_1\_\_t\_j}{$Is\_linear()$}
\If{$j<n$}
    \State $\mu_{j} \gets c_{j}+A_{C,j}^{T}\lambda_{C}
        +2D_{B_{O},j}^{T}x_{B_{O}}$
\Else
    \State $\mu_{j} \gets A_{C,j}^{T}\lambda_{C}$
\EndIf 
\EndFunction
\end{algorithmic}

\subsection{Ratio Test Step~2 implementation issues}
Since according to (\ref{def:mu_opt_cond}) $d_{t}=1 \Rightarrow \mu_{j}<0$ and $d_{t}=-1 \Rightarrow \mu_{j}>0$ for an entering variable, we distinguish these two cases and for each basic variable $x_{i}$ we distinguish whether  
%\begin{algorithm}
%\caption{Ratio Test Step~2 with upper bounding}
%\label{alg:ratio_test_step_2_0}
\begin{algorithmic}
\Function{ratio\_test\_2\_0\_\_mu\_i}{$B_{O},B_{S}, d_{t}$}
\State $i_{min} \gets -1, \quad d_{min} \gets 0, \quad  p_{min} \gets 1$
\If{$d_{t}=1$}
\Comment $\mu_{j} \leq 0$
    \ForAll{$i \gets 0,  \left|B_{O}\right| - 1$}
        \If{$p_{B_{O}}[i] < 0 \wedge f_{B_{O}}^{l}[i]=1$}
            \Comment check for lower bound
            \If{$d_{min}*p_{B_{O}}[i] > (x_{B_{O}}[i]-l[B_{O}[i]])*p_{min}$}
                \State $i_{min} \gets B_{O}[i], \quad lower \gets true$
                \State $d_{min} \gets x_{B_{O}}[i]-l[B_{O}[i]],
                            \quad p_{min} \gets p_{B_{O}}[i]$
            \EndIf
        \EndIf 
        \If{$p_{B_{O}}[i] > 0 \wedge f_{B_{O}}^{u}[i]=1$}
            \Comment check for upper bound
            \If{$d_{min}*p_{B_{O}}[i] < (u[B_{O}[i]]-x_{B_{O}}[i])*p_{min}$}
                \State $i_{min} \gets B_{O}[i], \quad lower \gets false$
                \State $d_{min} \gets u[B_{O}[i]]-x_{B_{O}}[i],
                            \quad p_{min} \gets -p_{B_{O}}[i]$
            \EndIf
        \EndIf 
    \EndFor
    \ForAll{$i \gets 0, \left|B_{S}\right| - 1$}
        \If{$p_{B_{S}}[i] < 0$}
            \If{$d_{min}*p_{B_{S}}[i] > x_{B_{S}}[i]*p_{min}$}
                \State $i_{min} \gets B_{S}[i],
                            \quad d_{min} \gets x_{B_{S}}[i],
                            \quad p_{min} \gets p_{B_{S}}[i]$
            \EndIf	
        \EndIf 
    \EndFor
\Else
\Comment $\mu_{j} \geq 0$
    \ForAll{$i \gets 0,  \left|B_{O}\right| - 1$}
        \If{$p_{B_{O}}[i] > 0 \wedge f_{B_{O}}^{l}[i]=1$}
            \Comment check for lower bound
            \If{$d_{min}*p_{B_{O}}[i] < (x_{B_{O}}[i]-l[B_{O}[i]])*p_{min}$}
                \State $i_{min} \gets B_{O}[i], \quad lower \gets true$
                \State $d_{min} \gets x_{B_{O}}[i]-l[B_{O}[i]],
                            \quad p_{min} \gets p_{B_{O}}[i]$
            \EndIf
        \EndIf
        \If{$p_{B_{O}}[i] < 0 \wedge f_{B_{O}}^{u}[i]=1$}
            \Comment check for upper bound
            \If{$d_{min}*p_{B_{O}}[i] > (u[B_{O}[i]]-x_{B_{O}}[i])*p_{min}$}
                \State $i_{min} \gets B_{O}[i], \quad lower \gets false$
                \State $d_{min} \gets u[B_{O}[i]]-x_{B_{O}}[i],
                            \quad p_{min} \gets -p_{B_{O}}[i]$
            \EndIf
        \EndIf 
    \EndFor
    \ForAll{$i \gets 0, \left|B_{S}\right| - 1$}
        \If{$p_{B_{S}}[i] > 0$}
            \If{$d_{min}*p_{B_{S}}[i] < x_{B_{S}}[i]*p_{min}$}
                \State $i_{min} \gets B_{S}[i],
                            \quad d_{min} \gets x_{B_{S}}[i],
                            \quad p_{min} \gets p_{B_{S}}[i]$
            \EndIf	
        \EndIf 
    \EndFor
\EndIf
\State \textbf{return} $(i_{min}, x_{min}, p_{min})$
\EndFunction
\end{algorithmic}
%\end{algorithm}


%\section{Updates implementation issues}
%Computing the new current solution in Ratio Test Step~1 according to
%Equation~(\ref{eq:Ratio_Test_1_Opt_sol_t}) and similarly for Ratio Test Step~2
%according to Equation~(\ref{eq:x_hat_B_mu_j}) directly with upper bounding is
%prohibitively expensive, since it involves at least a matrix vector
%multiplication plus an inner product. We therefore update the new solutions
%incrementally which is  

%\subsection{Updates for Ratio Test Step~1}
%In the first event only the values of the basic variables $x_{B}$ as well as 
%the value of the 'entering' variable $x_{j}$ of the current solution change,
%whereas the basis matrix remains the same. The basic variables $x_{B}^{\prime}$
%of the new solution $x^{\prime}$ are then according to
%Equations~(\ref{eq:Ratio_Test_1_Opt_sol_t}) and (\ref{def:t_min_j})
%given by
%\begin{equation}
%\left(
%\begin{array}{c}
%\lambda^{\prime} \\
%\hline
%x_{B}^{\prime}
%\end{array}
%\right)
%:=
%\left\{
%\begin{array}{ll}
%\left(
%\begin{array}{c}
%\lambda \\
%\hline
%x_{B} 
%\end{array}
%\right)
%+ b(j)\left(u_{j}-l_{j}\right)
%\left(
%\begin{array}{c}
%q_{\lambda} \\
%\hline
%q_{x}
%\end{array}
%\right)
%&
%\text{if $b(j) \neq 0$} \\
%\left(
%\begin{array}{c}
%\lambda \\
%\hline
%x_{B} 
%\end{array}
%\right)
%- l_{j}
%\left(
%\begin{array}{c}
%q_{\lambda} \\
%\hline
%q_{x}
%\end{array}
%\right)
%&
%\text{if $b(j)=0 \wedge d_{t}=-1$} \\
%\left(
%\begin{array}{c}
%\lambda \\
%\hline
%x_{B}
%\end{array}
%\right)
%+ u_{j}
%\left(
%\begin{array}{c}
%q_{\lambda} \\
%\hline
%q_{x}
%\end{array}
%\right)
%&
%\text{if $b(j)=0\wedge d_{t}=1$}
%\end{array}
%\right.
%\end{equation}
%and the nonbasic variables $x_{N}^{\prime}$ by
%\begin{equation}
%x_{N \setminus\{j\}}^{\prime}:=x_{N \setminus \{j\}}
%\quad
%x_{j}^{\prime}:=
%\left\{
%\begin{array}{ll}
%l_{j} 
%&
%\text{if $d_{t}=-1$} \\
%u_{j}
%&
%\text{if $d_{t}=1$} 
%\end{array}
%\right.
%\end{equation}

%In the second event both the values of the basic variables as well as the basis
%matrix change; the new set of basic variables is
%$B^{\prime}:=B \setminus \{i\}$
%\begin{equation}
%\left(
%\begin{array}{c}
%\lambda_{C}^{\prime} \\
%\hline
%x_{B}^{\prime}
%\end{array}
%\right)
%:=
%\left(
%\begin{array}{c}
%\lambda_{C} \\
%\hline
%x_{B}
%\end{array}
%\right)
%-t_{min}^{B}
%\left(
%\begin{array}{c}
%q_{\lambda} \\
%\hline
%q_{x}
%\end{array}
%\right)
%\end{equation}

\begin{thebibliography}{99}
\bibitem{Sven} Sven Sch\"{o}nherr. Quadratic Programming in Geometric Optimization:
Theory, Implementation, and Applications, Dissertation, Diss. ETH No 14738, ETH
Z\"{u}rich, Institute of Theoretical Computer Science, 2002.
\bibitem{Chvatal} Va\v{s}ek Chv\'{a}tal. \textit{Linear Programming}. W. H. Freeman and Company,
New York, Chapter 8, 1983 
\bibitem{Zielke} Gerhard Zielke. Inversion of Modified Symmetric Matrices. 
\textit{Journal of the Association for Computing Machinery}, Vol. 15, No. 3,
July 1968, pp. 402-408
\bibitem{Frans_Deg} Degeneracy
\end{thebibliography}
\end{document}